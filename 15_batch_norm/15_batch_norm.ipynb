{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je63V-baq52A"
      },
      "source": [
        "# Module 15: Batch Normalization\n",
        "\n",
        "**Stabilizing Deep Networks**\n",
        "\n",
        "---\n",
        "\n",
        "## Objectives\n",
        "\n",
        "By the end of this notebook, you will:\n",
        "- Understand internal covariate shift\n",
        "- Master batch normalization math\n",
        "- Know how to use BatchNorm in PyTorch\n",
        "- Understand train vs eval mode behavior\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6xeorFIq52D",
        "outputId": "011f8394-71c8-473c-a4b6-7589d5c010eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a0105c35f30>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5plX3NJq52G"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 1: The Problem\n",
        "\n",
        "---\n",
        "\n",
        "**Internal Covariate Shift**: As training progresses, the distribution of inputs to each layer changes, making learning unstable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZqpRzxHq52G"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 2: Batch Normalization\n",
        "\n",
        "---\n",
        "\n",
        "## 2.1 The Algorithm\n",
        "\n",
        "For a batch of inputs, normalize then scale and shift:\n",
        "\n",
        "$$\\hat{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}$$\n",
        "\n",
        "$$y_i = \\gamma \\hat{x}_i + \\beta$$\n",
        "\n",
        "Where:\n",
        "- $\\mu_B, \\sigma_B^2$ = batch mean and variance\n",
        "- $\\gamma, \\beta$ = learnable scale and shift\n",
        "- $\\epsilon$ = small constant for numerical stability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5png9Q9q52H",
        "outputId": "32b461b7-a667-47f4-e6fa-87beb647e5c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  mean=6.00, std=9.88\n",
            "Output: mean=0.00, std=1.00\n"
          ]
        }
      ],
      "source": [
        "# BatchNorm from scratch\n",
        "class BatchNorm1D:\n",
        "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
        "        # Learnable parameters\n",
        "        self.gamma = torch.ones(num_features)\n",
        "        self.beta = torch.zeros(num_features)\n",
        "\n",
        "        # Running statistics for inference\n",
        "        self.running_mean = torch.zeros(num_features)\n",
        "        self.running_var = torch.ones(num_features)\n",
        "\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        self.training = True\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if self.training:\n",
        "            # Use batch statistics\n",
        "            mean = x.mean(dim=0)\n",
        "            var = x.var(dim=0, unbiased=False)\n",
        "\n",
        "            # Update running statistics\n",
        "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * mean\n",
        "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * var\n",
        "        else:\n",
        "            # Use running statistics\n",
        "            mean = self.running_mean\n",
        "            var = self.running_var\n",
        "\n",
        "        # Normalize\n",
        "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
        "\n",
        "        # Scale and shift\n",
        "        return self.gamma * x_norm + self.beta\n",
        "\n",
        "# Test\n",
        "bn = BatchNorm1D(5)\n",
        "x = torch.randn(32, 5) * 10 + 5  # Mean ~5, Std ~10\n",
        "out = bn(x)\n",
        "\n",
        "print(f\"Input:  mean={x.mean():.2f}, std={x.std():.2f}\")\n",
        "print(f\"Output: mean={out.mean():.2f}, std={out.std():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbaApBylq52I"
      },
      "source": [
        "## 2.2 PyTorch BatchNorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLZeuZCbq52J",
        "outputId": "5717359c-5bf3-4b5b-ac90-f7cc7ce251bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learnable parameters:\n",
            "  gamma (weight): torch.Size([5])\n",
            "  beta (bias): torch.Size([5])\n",
            "\n",
            "Running statistics (buffers):\n",
            "  running_mean: torch.Size([5])\n",
            "  running_var: torch.Size([5])\n"
          ]
        }
      ],
      "source": [
        "# PyTorch BatchNorm\n",
        "bn = nn.BatchNorm1d(num_features=5)\n",
        "\n",
        "print(\"Learnable parameters:\")\n",
        "print(f\"  gamma (weight): {bn.weight.shape}\")\n",
        "print(f\"  beta (bias): {bn.bias.shape}\")\n",
        "\n",
        "print(\"\\nRunning statistics (buffers):\")\n",
        "print(f\"  running_mean: {bn.running_mean.shape}\")\n",
        "print(f\"  running_var: {bn.running_var.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNWu7h_gq52K",
        "outputId": "8be4c6ea-c174-43db-db65-f0d16cdc7fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train mode: 0.0000\n",
            "Eval mode: 1.3306\n"
          ]
        }
      ],
      "source": [
        "# Train vs Eval mode\n",
        "bn = nn.BatchNorm1d(5)\n",
        "x = torch.randn(32, 5) * 10 + 5\n",
        "\n",
        "# Training mode: uses batch statistics\n",
        "bn.train()\n",
        "out_train = bn(x)\n",
        "print(f\"Train mode: {out_train.mean():.4f}\")\n",
        "\n",
        "# Eval mode: uses running statistics\n",
        "bn.eval()\n",
        "out_eval = bn(x)\n",
        "print(f\"Eval mode: {out_eval.mean():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rNXMMM1q52K"
      },
      "source": [
        "## 2.3 Using in a Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvsUoGcvq52L",
        "outputId": "079a8dcb-8a59-412f-9f13-4b374dc435d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters: 270,346\n"
          ]
        }
      ],
      "source": [
        "class MLPWithBN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # BatchNorm BEFORE activation (most common)\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.fc3(x)  # No BN on output\n",
        "        return x\n",
        "\n",
        "model = MLPWithBN(784, 256, 10)\n",
        "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJxviULIq52M"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 3: Benefits\n",
        "\n",
        "---\n",
        "\n",
        "1. **Faster training**: Allows higher learning rates\n",
        "2. **Reduces sensitivity to initialization**\n",
        "3. **Acts as regularization** (slight noise from batch stats)\n",
        "4. **Enables deeper networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gi2Zpgoq52M"
      },
      "source": [
        "---\n",
        "\n",
        "# Key Points\n",
        "\n",
        "---\n",
        "\n",
        "- **Training**: Uses batch mean/var\n",
        "- **Inference**: Uses running mean/var\n",
        "- **Always call model.eval()** before inference!\n",
        "- Place BatchNorm before activation (most common)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qBmW1w1q52N"
      },
      "source": [
        "---\n",
        "\n",
        "## Next Module: [16 - Hyperparameter Tuning](../16_hyperparameters/16_hyperparameters.ipynb)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}