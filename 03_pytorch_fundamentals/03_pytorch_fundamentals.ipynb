{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoKD22cc2Ses"
      },
      "source": [
        "# Module 03: PyTorch Fundamentals\n",
        "\n",
        "**The Foundation of Deep Learning in PyTorch**\n",
        "\n",
        "---\n",
        "\n",
        "## Objectives\n",
        "\n",
        "By the end of this notebook, you will:\n",
        "- Master PyTorch tensor creation and operations\n",
        "- Understand the relationship between NumPy and PyTorch\n",
        "- Know how to use GPU acceleration\n",
        "- Understand automatic differentiation (autograd)\n",
        "\n",
        "**Prerequisites:**\n",
        "- [Module 01 - Python & Math Prerequisites](../01_python_math_prerequisites/01_prerequisites.ipynb)\n",
        "- [Module 02 - Introduction to Deep Learning](../02_intro_to_deep_learning/02_intro_deep_learning.ipynb)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q8jStzvO2Set",
        "outputId": "2b9c0574-b868-4191-b569-9da11abd003d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cpu\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeDkzLAZ2Seu"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 1: Tensors - The Core Data Structure\n",
        "\n",
        "---\n",
        "\n",
        "## 1.1 What is a Tensor?\n",
        "\n",
        "A **tensor** is a multi-dimensional array. It's the fundamental data structure in PyTorch.\n",
        "\n",
        "| Dimensions | Name | Example |\n",
        "|------------|------|--------|\n",
        "| 0 | Scalar | Single number: `5` |\n",
        "| 1 | Vector | List: `[1, 2, 3]` |\n",
        "| 2 | Matrix | 2D array: image (height x width) |\n",
        "| 3 | 3D Tensor | Batch of images, video frame |\n",
        "| 4+ | N-D Tensor | Batch of videos, etc. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u6QO2BR2Seu"
      },
      "source": [
        "## 1.2 Creating Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NEbnsdax2Seu",
        "outputId": "a4304700-0164-487d-9c3f-3f02e0ad983b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From list: tensor([1, 2, 3])\n",
            "\n",
            "2D tensor:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ],
      "source": [
        "# From Python list\n",
        "t1 = torch.tensor([1, 2, 3])\n",
        "print(f\"From list: {t1}\")\n",
        "\n",
        "# 2D tensor\n",
        "t2 = torch.tensor([[1, 2, 3],\n",
        "                   [4, 5, 6]])\n",
        "print(f\"\\n2D tensor:\\n{t2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "soYmUK7i2Sev",
        "outputId": "5e8fd666-4445-46c8-98bd-bac121b2f31d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zeros (3x4):\n",
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "\n",
            "Identity (3x3):\n",
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# Common initialization patterns\n",
        "zeros = torch.zeros(3, 4)       # 3x4 zeros\n",
        "ones = torch.ones(2, 3)         # 2x3 ones\n",
        "eye = torch.eye(3)              # 3x3 identity\n",
        "empty = torch.empty(2, 2)       # Uninitialized (random memory)\n",
        "\n",
        "print(f\"Zeros (3x4):\\n{zeros}\")\n",
        "print(f\"\\nIdentity (3x3):\\n{eye}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "maKNxpCN2Sev",
        "outputId": "400ed917-7212-4c36-8254-ac87e62791eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uniform [0,1):\n",
            "tensor([[0.4334, 0.4454, 0.9643],\n",
            "        [0.0355, 0.2027, 0.3789]])\n",
            "\n",
            "Normal (0,1):\n",
            "tensor([[ 0.3341,  0.1154, -0.5637],\n",
            "        [ 1.8133, -2.7845, -1.2030]])\n",
            "\n",
            "Random integers [0,10):\n",
            "tensor([[5, 3, 1],\n",
            "        [5, 8, 3]])\n"
          ]
        }
      ],
      "source": [
        "# Random tensors - essential for weight initialization\n",
        "rand_uniform = torch.rand(2, 3)      # Uniform [0, 1)\n",
        "rand_normal = torch.randn(2, 3)      # Standard normal N(0, 1)\n",
        "rand_int = torch.randint(0, 10, (2, 3))  # Random integers [0, 10)\n",
        "\n",
        "print(f\"Uniform [0,1):\\n{rand_uniform}\")\n",
        "print(f\"\\nNormal (0,1):\\n{rand_normal}\")\n",
        "print(f\"\\nRandom integers [0,10):\\n{rand_int}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KNFfxuGL2Sev",
        "outputId": "079bc912-1770-4e60-8813-b22878ea105c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arange (0 to 10 step 2): tensor([0, 2, 4, 6, 8])\n",
            "Linspace (0 to 1, 5 points): tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
          ]
        }
      ],
      "source": [
        "# Range and linspace\n",
        "arange = torch.arange(0, 10, 2)      # Start, end, step\n",
        "linspace = torch.linspace(0, 1, 5)   # Start, end, num_points\n",
        "\n",
        "print(f\"Arange (0 to 10 step 2): {arange}\")\n",
        "print(f\"Linspace (0 to 1, 5 points): {linspace}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GdomocOL2Sev",
        "outputId": "4bd8162d-0274-4b6f-9877-d4d8f17ec14c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "\n",
            "Zeros like:\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "# Create tensor with same properties as another\n",
        "x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "\n",
        "zeros_like = torch.zeros_like(x)     # Same shape, dtype, device\n",
        "ones_like = torch.ones_like(x)\n",
        "rand_like = torch.randn_like(x)\n",
        "\n",
        "print(f\"Original:\\n{x}\")\n",
        "print(f\"\\nZeros like:\\n{zeros_like}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWksgFHE2Sev"
      },
      "source": [
        "## 1.3 Tensor Attributes\n",
        "\n",
        "Every tensor has three key attributes:\n",
        "- **shape**: Dimensions of the tensor\n",
        "- **dtype**: Data type of elements\n",
        "- **device**: Where the tensor lives (CPU or GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZOARZ8Yt2Sev",
        "outputId": "07a6e65d-f24b-4fb7-f479-292e19a078ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor:\n",
            "tensor([[-1.7375,  2.6604, -0.3214, -1.1554],\n",
            "        [-0.7060, -0.1635, -0.7593,  0.0719],\n",
            "        [-0.1344,  0.8519, -1.1914, -0.1875]])\n",
            "\n",
            "Shape: torch.Size([3, 4])\n",
            "Dtype: torch.float32\n",
            "Device: cpu\n",
            "Number of dimensions: 2\n",
            "Total elements: 12\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(3, 4)\n",
        "\n",
        "print(f\"Tensor:\\n{x}\")\n",
        "print(f\"\\nShape: {x.shape}\")        # or x.size()\n",
        "print(f\"Dtype: {x.dtype}\")\n",
        "print(f\"Device: {x.device}\")\n",
        "print(f\"Number of dimensions: {x.ndim}\")\n",
        "print(f\"Total elements: {x.numel()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VoKkNKoz2Sew",
        "outputId": "fb035721-993b-4e5c-9e48-8a9cc35ba602",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float32: torch.float32\n",
            "float64: torch.float64\n",
            "int64: torch.int64\n",
            "bool: torch.bool\n"
          ]
        }
      ],
      "source": [
        "# Data types\n",
        "# float32 is the default and most common for deep learning\n",
        "float_tensor = torch.tensor([1.0, 2.0], dtype=torch.float32)\n",
        "double_tensor = torch.tensor([1.0, 2.0], dtype=torch.float64)\n",
        "int_tensor = torch.tensor([1, 2], dtype=torch.int64)\n",
        "bool_tensor = torch.tensor([True, False], dtype=torch.bool)\n",
        "\n",
        "print(f\"float32: {float_tensor.dtype}\")\n",
        "print(f\"float64: {double_tensor.dtype}\")\n",
        "print(f\"int64: {int_tensor.dtype}\")\n",
        "print(f\"bool: {bool_tensor.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcpejZNK2Sew"
      },
      "source": [
        "### Why float32?\n",
        "\n",
        "- **Memory efficient**: Half the memory of float64\n",
        "- **Faster on GPU**: GPUs are optimized for float32\n",
        "- **Sufficient precision**: Neural networks don't need float64 precision\n",
        "\n",
        "For training very large models, even float16 (half precision) is used!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0REryiu2Sew"
      },
      "source": [
        "## 1.4 Reshaping Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4DZ7ZVpp2Sew",
        "outputId": "6a5dfc96-349d-43eb-c6e0-bd7cc8ddfbca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
            "Shape: torch.Size([12])\n",
            "\n",
            "Reshaped (3, 4):\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "\n",
            "Viewed (4, 3):\n",
            "tensor([[ 0,  1,  2],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n",
            "\n",
            "Auto reshape (2, -1) = (2, 6):\n",
            "tensor([[ 0,  1,  2,  3,  4,  5],\n",
            "        [ 6,  7,  8,  9, 10, 11]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12)\n",
        "print(f\"Original: {x}\")\n",
        "print(f\"Shape: {x.shape}\")\n",
        "\n",
        "# Reshape\n",
        "reshaped = x.reshape(3, 4)\n",
        "print(f\"\\nReshaped (3, 4):\\n{reshaped}\")\n",
        "\n",
        "# View (requires contiguous memory, but no copy)\n",
        "viewed = x.view(4, 3)\n",
        "print(f\"\\nViewed (4, 3):\\n{viewed}\")\n",
        "\n",
        "# -1 means \"infer this dimension\"\n",
        "auto_reshape = x.reshape(2, -1)  # 2 rows, auto columns\n",
        "print(f\"\\nAuto reshape (2, -1) = (2, 6):\\n{auto_reshape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GJ7-su4O2Sew",
        "outputId": "b0da88b4-441d-4e0b-f74e-7cf404b43de0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: torch.Size([3, 4])\n",
            "After unsqueeze(0): torch.Size([1, 3, 4])\n",
            "After unsqueeze(-1): torch.Size([3, 4, 1])\n",
            "\n",
            "Before squeeze: torch.Size([1, 3, 1, 4])\n",
            "After squeeze: torch.Size([3, 4])\n"
          ]
        }
      ],
      "source": [
        "# Adding/removing dimensions\n",
        "x = torch.randn(3, 4)\n",
        "print(f\"Original shape: {x.shape}\")\n",
        "\n",
        "# Unsqueeze: add dimension\n",
        "x_unsqueeze = x.unsqueeze(0)  # Add at position 0\n",
        "print(f\"After unsqueeze(0): {x_unsqueeze.shape}\")\n",
        "\n",
        "x_unsqueeze2 = x.unsqueeze(-1)  # Add at last position\n",
        "print(f\"After unsqueeze(-1): {x_unsqueeze2.shape}\")\n",
        "\n",
        "# Squeeze: remove dimensions of size 1\n",
        "y = torch.randn(1, 3, 1, 4)\n",
        "print(f\"\\nBefore squeeze: {y.shape}\")\n",
        "print(f\"After squeeze: {y.squeeze().shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vfl7S9mk2Sew",
        "outputId": "c4353d23-5d98-4e9c-e21b-a7b6250c43ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: torch.Size([2, 3, 4])\n",
            "Fully flattened: torch.Size([24])\n",
            "Flatten from dim 1: torch.Size([2, 12])\n"
          ]
        }
      ],
      "source": [
        "# Flatten\n",
        "x = torch.randn(2, 3, 4)\n",
        "print(f\"Original shape: {x.shape}\")\n",
        "\n",
        "flat = x.flatten()  # Completely flat\n",
        "print(f\"Fully flattened: {flat.shape}\")\n",
        "\n",
        "# Flatten starting from dimension 1 (keep batch)\n",
        "batch_flat = x.flatten(start_dim=1)\n",
        "print(f\"Flatten from dim 1: {batch_flat.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xfvXA9y2Sey"
      },
      "source": [
        "### Deep Learning Context\n",
        "\n",
        "Common reshape patterns:\n",
        "- **Flatten before dense layer**: (batch, C, H, W) -> (batch, C*H*W)\n",
        "- **Add batch dimension**: (features,) -> (1, features)\n",
        "- **Prepare for broadcasting**: (batch, features) -> (batch, features, 1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzLebvS32Sez"
      },
      "source": [
        "## 1.5 Tensor Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9Rg5z7JP2Sez",
        "outputId": "1cbae216-aea2-4314-f140-6fd5ed59a2d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a = tensor([1., 2., 3.])\n",
            "b = tensor([4., 5., 6.])\n",
            "\n",
            "a + b = tensor([5., 7., 9.])\n",
            "a * b = tensor([ 4., 10., 18.])\n",
            "a / b = tensor([0.2500, 0.4000, 0.5000])\n",
            "a ** 2 = tensor([1., 4., 9.])\n"
          ]
        }
      ],
      "source": [
        "# Element-wise operations\n",
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.tensor([4.0, 5.0, 6.0])\n",
        "\n",
        "print(f\"a = {a}\")\n",
        "print(f\"b = {b}\")\n",
        "print(f\"\\na + b = {a + b}\")\n",
        "print(f\"a * b = {a * b}\")\n",
        "print(f\"a / b = {a / b}\")\n",
        "print(f\"a ** 2 = {a ** 2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bJ3GzME02Sez",
        "outputId": "1d54ec72-9f39-47ed-ed1c-42ba6bfd6491",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([0., 1., 2.])\n",
            "exp(x) = tensor([1.0000, 2.7183, 7.3891])\n",
            "log(exp(x)) = tensor([0., 1., 2.])\n",
            "sqrt(x+1) = tensor([1.0000, 1.4142, 1.7321])\n",
            "sin(x) = tensor([0.0000, 0.8415, 0.9093])\n",
            "abs(x-1) = tensor([1., 0., 1.])\n"
          ]
        }
      ],
      "source": [
        "# Mathematical functions\n",
        "x = torch.tensor([0.0, 1.0, 2.0])\n",
        "\n",
        "print(f\"x = {x}\")\n",
        "print(f\"exp(x) = {torch.exp(x)}\")\n",
        "print(f\"log(exp(x)) = {torch.log(torch.exp(x))}\")\n",
        "print(f\"sqrt(x+1) = {torch.sqrt(x + 1)}\")\n",
        "print(f\"sin(x) = {torch.sin(x)}\")\n",
        "print(f\"abs(x-1) = {torch.abs(x - 1)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IG6OLY2F2Sez",
        "outputId": "2a79e173-bae0-472d-d350-abc1af2fe81f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor:\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "\n",
            "Sum (all): 21.0\n",
            "Sum (dim=0, columns): tensor([5., 7., 9.])\n",
            "Sum (dim=1, rows): tensor([ 6., 15.])\n",
            "Mean: 3.5\n",
            "Std: 1.8708287477493286\n",
            "Max: 6.0\n",
            "Argmax: 5\n"
          ]
        }
      ],
      "source": [
        "# Reduction operations\n",
        "x = torch.tensor([[1.0, 2.0, 3.0],\n",
        "                  [4.0, 5.0, 6.0]])\n",
        "\n",
        "print(f\"Tensor:\\n{x}\")\n",
        "print(f\"\\nSum (all): {x.sum()}\")\n",
        "print(f\"Sum (dim=0, columns): {x.sum(dim=0)}\")\n",
        "print(f\"Sum (dim=1, rows): {x.sum(dim=1)}\")\n",
        "print(f\"Mean: {x.mean()}\")\n",
        "print(f\"Std: {x.std()}\")\n",
        "print(f\"Max: {x.max()}\")\n",
        "print(f\"Argmax: {x.argmax()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vgaB_b4J2Sez",
        "outputId": "3b039bcd-ac80-4f0d-d701-5bd578c7e57f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A shape: torch.Size([3, 4])\n",
            "B shape: torch.Size([4, 2])\n",
            "A @ B shape: torch.Size([3, 2])\n"
          ]
        }
      ],
      "source": [
        "# Matrix operations\n",
        "A = torch.randn(3, 4)\n",
        "B = torch.randn(4, 2)\n",
        "\n",
        "# Matrix multiplication\n",
        "C = A @ B  # or torch.matmul(A, B)\n",
        "print(f\"A shape: {A.shape}\")\n",
        "print(f\"B shape: {B.shape}\")\n",
        "print(f\"A @ B shape: {C.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-LmPpIoA2Sez",
        "outputId": "c2a18603-17f2-44ef-e731-f1cdd0405711",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v1 . v2 = 32.0\n"
          ]
        }
      ],
      "source": [
        "# Dot product (1D vectors)\n",
        "v1 = torch.tensor([1.0, 2.0, 3.0])\n",
        "v2 = torch.tensor([4.0, 5.0, 6.0])\n",
        "\n",
        "dot = torch.dot(v1, v2)\n",
        "print(f\"v1 . v2 = {dot}\")  # 1*4 + 2*5 + 3*6 = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVN6nBI82Sez"
      },
      "source": [
        "## 1.6 Indexing and Slicing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bPQxdEiL2Sez",
        "outputId": "96b0a48f-6c86-44c2-ee60-428569e6106d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor:\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "\n",
            "x[0, 0] = 0\n",
            "x[1, 2] = 6\n",
            "x[-1] (last row) = tensor([ 8,  9, 10, 11])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12).reshape(3, 4)\n",
        "print(f\"Tensor:\\n{x}\")\n",
        "\n",
        "# Basic indexing\n",
        "print(f\"\\nx[0, 0] = {x[0, 0]}\")\n",
        "print(f\"x[1, 2] = {x[1, 2]}\")\n",
        "print(f\"x[-1] (last row) = {x[-1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uwQubzx42Sez",
        "outputId": "16c2316a-2df8-468d-c435-66cebdb59753",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First two rows:\n",
            "tensor([[0, 1, 2, 3],\n",
            "        [4, 5, 6, 7]])\n",
            "\n",
            "Columns 1 to 3:\n",
            "tensor([[ 1,  2],\n",
            "        [ 5,  6],\n",
            "        [ 9, 10]])\n",
            "\n",
            "Every other row:\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 8,  9, 10, 11]])\n"
          ]
        }
      ],
      "source": [
        "# Slicing\n",
        "print(f\"First two rows:\\n{x[:2]}\")\n",
        "print(f\"\\nColumns 1 to 3:\\n{x[:, 1:3]}\")\n",
        "print(f\"\\nEvery other row:\\n{x[::2]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zKGZZPCv2Sez",
        "outputId": "fc07b2ad-e0fe-4879-f622-942c5608f3fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([-0.5190,  0.1375,  0.5323,  0.2556,  0.3060])\n",
            "x > 0: tensor([False,  True,  True,  True,  True])\n",
            "x[x > 0] = tensor([0.1375, 0.5323, 0.2556, 0.3060])\n"
          ]
        }
      ],
      "source": [
        "# Boolean indexing\n",
        "x = torch.randn(5)\n",
        "print(f\"x = {x}\")\n",
        "print(f\"x > 0: {x > 0}\")\n",
        "print(f\"x[x > 0] = {x[x > 0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naSZ4pb62Se0"
      },
      "source": [
        "## 1.7 In-place Operations\n",
        "\n",
        "Operations with `_` suffix modify the tensor in-place."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WxQslX_X2Se0",
        "outputId": "8e576c9b-5c17-4341-ab56-0e737219a661",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: tensor([1., 2., 3.])\n",
            "After add_(10): tensor([11., 12., 13.])\n",
            "After mul_(2): tensor([22., 24., 26.])\n",
            "After zero_(): tensor([0., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(f\"Original: {x}\")\n",
        "\n",
        "# In-place operations (modify x directly)\n",
        "x.add_(10)  # x = x + 10\n",
        "print(f\"After add_(10): {x}\")\n",
        "\n",
        "x.mul_(2)   # x = x * 2\n",
        "print(f\"After mul_(2): {x}\")\n",
        "\n",
        "x.zero_()   # x = 0\n",
        "print(f\"After zero_(): {x}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgK253Wa2Se0"
      },
      "source": [
        "### Warning!\n",
        "\n",
        "In-place operations can cause problems with autograd. Avoid them when tracking gradients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxQ1IvLV2Se0"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 2: PyTorch and NumPy\n",
        "\n",
        "---\n",
        "\n",
        "## 2.1 Conversion Between NumPy and PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6MYciD3x2Se0",
        "outputId": "6ee6281a-049a-4897-a3b9-6fb39c7a068d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy array: [1 2 3 4 5]\n",
            "Tensor (shared): tensor([1, 2, 3, 4, 5])\n",
            "Tensor (copied): tensor([1, 2, 3, 4, 5])\n"
          ]
        }
      ],
      "source": [
        "# NumPy to PyTorch\n",
        "np_array = np.array([1, 2, 3, 4, 5])\n",
        "print(f\"NumPy array: {np_array}\")\n",
        "\n",
        "# Method 1: from_numpy (shares memory!)\n",
        "tensor_shared = torch.from_numpy(np_array)\n",
        "print(f\"Tensor (shared): {tensor_shared}\")\n",
        "\n",
        "# Method 2: torch.tensor (copies data)\n",
        "tensor_copied = torch.tensor(np_array)\n",
        "print(f\"Tensor (copied): {tensor_copied}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7whlvQNm2Se0",
        "outputId": "b3428c71-9389-4d80-848f-d6792c9ace4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: NumPy = [1 2 3], Tensor = tensor([1, 2, 3])\n",
            "After modifying NumPy: NumPy = [999   2   3], Tensor = tensor([999,   2,   3])\n",
            "The tensor changed too! They share memory.\n"
          ]
        }
      ],
      "source": [
        "# Memory sharing demonstration\n",
        "np_arr = np.array([1, 2, 3])\n",
        "t_shared = torch.from_numpy(np_arr)\n",
        "\n",
        "print(f\"Before: NumPy = {np_arr}, Tensor = {t_shared}\")\n",
        "\n",
        "# Modify NumPy array\n",
        "np_arr[0] = 999\n",
        "\n",
        "print(f\"After modifying NumPy: NumPy = {np_arr}, Tensor = {t_shared}\")\n",
        "print(\"The tensor changed too! They share memory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hFLXTPue2Se1",
        "outputId": "3ea223fa-996b-4310-bc56-090a55b4ad00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor to NumPy: [1. 2. 3.]\n",
            "Type: <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# PyTorch to NumPy\n",
        "tensor = torch.tensor([1.0, 2.0, 3.0])\n",
        "\n",
        "# .numpy() shares memory (CPU tensor only)\n",
        "np_from_tensor = tensor.numpy()\n",
        "print(f\"Tensor to NumPy: {np_from_tensor}\")\n",
        "print(f\"Type: {type(np_from_tensor)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5d4e_tx2Se1"
      },
      "source": [
        "## 2.2 Key Differences\n",
        "\n",
        "| Feature | NumPy | PyTorch |\n",
        "|---------|-------|--------|\n",
        "| GPU support | No | Yes |\n",
        "| Automatic differentiation | No | Yes |\n",
        "| Deep learning layers | No | Yes |\n",
        "| Naming | ndarray | tensor |\n",
        "| Primary use | Numerical computing | Deep learning |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7fTHAxg2Se1"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 3: GPU Acceleration\n",
        "\n",
        "---\n",
        "\n",
        "## 3.1 Device Management"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5LcwVIMt2Se1",
        "outputId": "d1a6429a-8453-41f3-9506-2f93ec01826d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "    print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
        "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "cc_5AkUu2Se1",
        "outputId": "bb2c8b6b-740c-4352-a5f0-9ddb515decf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Device-agnostic code pattern\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Qpn7ZwEs2Se4",
        "outputId": "ae6f7b51-936c-4c5c-9fb9-4913346cb8e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original device: cpu\n",
            "After .to(device): cpu\n"
          ]
        }
      ],
      "source": [
        "# Moving tensors to device\n",
        "x = torch.randn(3, 4)\n",
        "print(f\"Original device: {x.device}\")\n",
        "\n",
        "# Move to device (GPU if available, else stays on CPU)\n",
        "x = x.to(device)\n",
        "print(f\"After .to(device): {x.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "qTbOrdeQ2Se5",
        "outputId": "54ba1c44-4363-4fbd-fa51-39d6efe55a7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created on device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Create tensor directly on device\n",
        "y = torch.randn(3, 4, device=device)\n",
        "print(f\"Created on device: {y.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kKODj69n2Se5",
        "outputId": "340381d1-94ac-416f-d649-b6defd13c503",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After .cpu(): cpu\n",
            "As NumPy array: [[ 0.07296569 -1.0064623   0.11911819 -0.34662852]\n",
            " [-0.89221215  0.47555807 -1.100417   -0.17303501]\n",
            " [ 0.34650838  0.9472258   0.49671686 -1.7477542 ]]\n"
          ]
        }
      ],
      "source": [
        "# Moving back to CPU (needed for NumPy, plotting, etc.)\n",
        "x_cpu = x.cpu()\n",
        "print(f\"After .cpu(): {x_cpu.device}\")\n",
        "\n",
        "# Convert to NumPy (must be on CPU)\n",
        "x_numpy = x_cpu.numpy()\n",
        "print(f\"As NumPy array: {x_numpy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQNQTDVA2Se5"
      },
      "source": [
        "## 3.2 Operations Across Devices\n",
        "\n",
        "**Important:** All tensors in an operation must be on the same device!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XkqaMZ0R2Se5",
        "outputId": "b271ff35-881b-4a30-883a-5f16c6c6647e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result device: cpu\n"
          ]
        }
      ],
      "source": [
        "# This would cause an error if one tensor is on GPU and one on CPU\n",
        "# a_cpu = torch.randn(3)\n",
        "# b_gpu = torch.randn(3, device='cuda')\n",
        "# c = a_cpu + b_gpu  # ERROR!\n",
        "\n",
        "# Correct approach: move to same device\n",
        "a = torch.randn(3, device=device)\n",
        "b = torch.randn(3, device=device)\n",
        "c = a + b  # Works!\n",
        "print(f\"Result device: {c.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNy1PS8E2Se5"
      },
      "source": [
        "## 3.3 GPU Speed Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Fwxd5jHo2Se5",
        "outputId": "79a83acb-41eb-49fe-fd18-f88a8f53f02c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size 1000x1000: CPU=0.0454s (GPU not available)\n",
            "Size 2000x2000: CPU=0.2785s (GPU not available)\n",
            "Size 4000x4000: CPU=1.9943s (GPU not available)\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Matrix multiplication benchmark\n",
        "sizes = [1000, 2000, 4000]\n",
        "\n",
        "for size in sizes:\n",
        "    # CPU\n",
        "    a_cpu = torch.randn(size, size)\n",
        "    b_cpu = torch.randn(size, size)\n",
        "\n",
        "    start = time.time()\n",
        "    c_cpu = a_cpu @ b_cpu\n",
        "    cpu_time = time.time() - start\n",
        "\n",
        "    # GPU (if available)\n",
        "    if torch.cuda.is_available():\n",
        "        a_gpu = a_cpu.cuda()\n",
        "        b_gpu = b_cpu.cuda()\n",
        "\n",
        "        torch.cuda.synchronize()  # Wait for GPU operations\n",
        "        start = time.time()\n",
        "        c_gpu = a_gpu @ b_gpu\n",
        "        torch.cuda.synchronize()\n",
        "        gpu_time = time.time() - start\n",
        "\n",
        "        speedup = cpu_time / gpu_time\n",
        "        print(f\"Size {size}x{size}: CPU={cpu_time:.4f}s, GPU={gpu_time:.4f}s, Speedup={speedup:.1f}x\")\n",
        "    else:\n",
        "        print(f\"Size {size}x{size}: CPU={cpu_time:.4f}s (GPU not available)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dTfY3r72Se5"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 4: Automatic Differentiation (Autograd)\n",
        "\n",
        "---\n",
        "\n",
        "This is one of PyTorch's most powerful features. It automatically computes gradients, which is essential for training neural networks.\n",
        "\n",
        "## 4.1 The Concept\n",
        "\n",
        "Recall from calculus: to minimize a loss function, we need its gradient.\n",
        "\n",
        "**Manually computing gradients is:**\n",
        "- Tedious for complex networks\n",
        "- Error-prone\n",
        "- Hard to modify\n",
        "\n",
        "**Autograd:**\n",
        "- Tracks operations on tensors\n",
        "- Automatically computes gradients\n",
        "- Handles arbitrarily complex graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axfR9wdf2Se5"
      },
      "source": [
        "## 4.2 requires_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qt8CwYNa2Se5",
        "outputId": "e059073e-150e-4da7-9f1b-8aa8961af278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requires_grad: False\n",
            "requires_grad: True\n"
          ]
        }
      ],
      "source": [
        "# By default, tensors don't track gradients\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(f\"requires_grad: {x.requires_grad}\")\n",
        "\n",
        "# Enable gradient tracking\n",
        "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "print(f\"requires_grad: {x.requires_grad}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "gIapnzY02Se5",
        "outputId": "be9a633e-1155-4a43-d883-ca5ce41a3075",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([2.], requires_grad=True)\n",
            "y = x^2 = tensor([4.], grad_fn=<PowBackward0>)\n",
            "z = 2*y = tensor([8.], grad_fn=<MulBackward0>)\n",
            "\n",
            "y.grad_fn: <PowBackward0 object at 0x7bb00a7b9ae0>\n",
            "z.grad_fn: <MulBackward0 object at 0x7bb00a7b9ae0>\n"
          ]
        }
      ],
      "source": [
        "# When requires_grad=True, operations build a computation graph\n",
        "x = torch.tensor([2.0], requires_grad=True)\n",
        "y = x ** 2  # y = x^2\n",
        "z = 2 * y   # z = 2 * x^2\n",
        "\n",
        "print(f\"x = {x}\")\n",
        "print(f\"y = x^2 = {y}\")\n",
        "print(f\"z = 2*y = {z}\")\n",
        "print(f\"\\ny.grad_fn: {y.grad_fn}\")  # Tracks how y was created\n",
        "print(f\"z.grad_fn: {z.grad_fn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdj5XcLp2Se5"
      },
      "source": [
        "## 4.3 Computing Gradients with backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-VrGJyW72Se5",
        "outputId": "ba208bb2-41bb-4770-d181-c077b6b11c8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = 2.0\n",
            "y = x^2 = 4.0\n",
            "dy/dx = 2x = 4.0\n"
          ]
        }
      ],
      "source": [
        "# Simple example: y = x^2, find dy/dx\n",
        "x = torch.tensor([2.0], requires_grad=True)\n",
        "y = x ** 2\n",
        "\n",
        "# Compute gradients\n",
        "y.backward()  # dy/dx\n",
        "\n",
        "print(f\"x = {x.item()}\")\n",
        "print(f\"y = x^2 = {y.item()}\")\n",
        "print(f\"dy/dx = 2x = {x.grad.item()}\")  # 2 * 2 = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Fvqn3M6q2Se6",
        "outputId": "fb7077c8-1ee7-4e37-d259-5b7779ba07fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = 3.0\n",
            "y = (x+2)^2 = 25.0\n",
            "dy/dx = 2(x+2) = 10.0\n"
          ]
        }
      ],
      "source": [
        "# More complex example: chain rule\n",
        "# y = (x + 2)^2\n",
        "# dy/dx = 2(x + 2)\n",
        "\n",
        "x = torch.tensor([3.0], requires_grad=True)\n",
        "y = (x + 2) ** 2\n",
        "\n",
        "y.backward()\n",
        "\n",
        "print(f\"x = {x.item()}\")\n",
        "print(f\"y = (x+2)^2 = {y.item()}\")\n",
        "print(f\"dy/dx = 2(x+2) = {x.grad.item()}\")  # 2 * (3 + 2) = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Qd6DCcF52Se6",
        "outputId": "fb23daab-ae82-4644-f00f-a9884ebd6a50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z = x^2 + y^2 = 25.0\n",
            "dz/dx = 2x = 6.0\n",
            "dz/dy = 2y = 8.0\n"
          ]
        }
      ],
      "source": [
        "# Multiple variables\n",
        "# z = x^2 + y^2\n",
        "# dz/dx = 2x, dz/dy = 2y\n",
        "\n",
        "x = torch.tensor([3.0], requires_grad=True)\n",
        "y = torch.tensor([4.0], requires_grad=True)\n",
        "\n",
        "z = x**2 + y**2\n",
        "\n",
        "z.backward()\n",
        "\n",
        "print(f\"z = x^2 + y^2 = {z.item()}\")\n",
        "print(f\"dz/dx = 2x = {x.grad.item()}\")  # 6\n",
        "print(f\"dz/dy = 2y = {y.grad.item()}\")  # 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43drtBmz2Se6"
      },
      "source": [
        "## 4.4 Vector-Valued Functions\n",
        "\n",
        "When the output is a vector, we need to provide a gradient argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "HsCmfRjz2Se6",
        "outputId": "15631f23-3f85-4d88-e348-658ab09e8943",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x = tensor([1., 2., 3.], requires_grad=True)\n",
            "y = x^2 = tensor([1., 4., 9.], grad_fn=<PowBackward0>)\n",
            "loss = sum(y) = 14.0\n",
            "d(loss)/dx = 2x = tensor([2., 4., 6.])\n"
          ]
        }
      ],
      "source": [
        "# For neural networks, we usually sum the loss first\n",
        "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "y = x ** 2\n",
        "loss = y.sum()  # Scalar output\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print(f\"x = {x}\")\n",
        "print(f\"y = x^2 = {y}\")\n",
        "print(f\"loss = sum(y) = {loss.item()}\")\n",
        "print(f\"d(loss)/dx = 2x = {x.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEbZ4t_42Se7"
      },
      "source": [
        "## 4.5 Gradient Accumulation\n",
        "\n",
        "**Important:** Gradients accumulate by default! You must zero them before each backward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "r7TclacO2Se7",
        "outputId": "e597b007-ced5-468c-ecff-5920be095d6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After first backward: grad = 4.0\n",
            "After second backward (accumulated!): grad = 8.0\n",
            "After zeroing and backward: grad = 4.0\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([2.0], requires_grad=True)\n",
        "\n",
        "# First backward\n",
        "y = x ** 2\n",
        "y.backward()\n",
        "print(f\"After first backward: grad = {x.grad.item()}\")\n",
        "\n",
        "# Second backward (without zeroing)\n",
        "y = x ** 2\n",
        "y.backward()\n",
        "print(f\"After second backward (accumulated!): grad = {x.grad.item()}\")\n",
        "\n",
        "# Correct way: zero gradients first\n",
        "x.grad.zero_()\n",
        "y = x ** 2\n",
        "y.backward()\n",
        "print(f\"After zeroing and backward: grad = {x.grad.item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIk_wKTJ2Se7"
      },
      "source": [
        "## 4.6 Detaching and No-Grad Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "CZob2hus2Se7",
        "outputId": "b1b922f1-fc33-4acf-cf31-b5b9c8066e19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y requires_grad: True\n",
            "y_detached requires_grad: False\n"
          ]
        }
      ],
      "source": [
        "# Detach: remove from computation graph\n",
        "x = torch.tensor([2.0], requires_grad=True)\n",
        "y = x ** 2\n",
        "\n",
        "y_detached = y.detach()  # No longer tracks gradients\n",
        "print(f\"y requires_grad: {y.requires_grad}\")\n",
        "print(f\"y_detached requires_grad: {y_detached.requires_grad}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "LVpSDK5M2Se7",
        "outputId": "4ffccb1f-8488-408e-d9de-c2526cf3a528",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal: y.requires_grad = True\n",
            "In no_grad: y.requires_grad = False\n"
          ]
        }
      ],
      "source": [
        "# torch.no_grad(): disable gradient tracking temporarily\n",
        "# Used during inference/evaluation\n",
        "\n",
        "x = torch.tensor([2.0], requires_grad=True)\n",
        "\n",
        "# Normal operation (tracks gradients)\n",
        "y = x ** 2\n",
        "print(f\"Normal: y.requires_grad = {y.requires_grad}\")\n",
        "\n",
        "# With no_grad\n",
        "with torch.no_grad():\n",
        "    y_no_grad = x ** 2\n",
        "    print(f\"In no_grad: y.requires_grad = {y_no_grad.requires_grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-5KFY4B2Se7"
      },
      "source": [
        "### When to Use No-Grad\n",
        "\n",
        "- **Inference/Evaluation**: No need to compute gradients\n",
        "- **Memory saving**: Gradient tracking uses memory\n",
        "- **Speed**: Slightly faster without tracking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfMMyGa92Se7"
      },
      "source": [
        "## 4.7 A Neural Network Gradient Example\n",
        "\n",
        "Let's see how autograd works for a simple one-layer network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "OYmEQzwZ2Se7",
        "outputId": "aa813231-a9ee-4bda-deeb-a27db05e550a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w = 0.500, b = 0.100\n",
            "z = w*x + b = 0.600\n",
            "y = sigmoid(z) = 0.646\n",
            "loss = (y - target)^2 = 0.417\n",
            "\n",
            "Gradients:\n",
            "d(loss)/dw = 0.2954\n",
            "d(loss)/db = 0.2954\n"
          ]
        }
      ],
      "source": [
        "# Simple neuron: y = sigmoid(w*x + b)\n",
        "# Loss = (y - target)^2\n",
        "\n",
        "# Input\n",
        "x = torch.tensor([1.0])\n",
        "target = torch.tensor([0.0])\n",
        "\n",
        "# Learnable parameters\n",
        "w = torch.tensor([0.5], requires_grad=True)\n",
        "b = torch.tensor([0.1], requires_grad=True)\n",
        "\n",
        "# Forward pass\n",
        "z = w * x + b\n",
        "y = torch.sigmoid(z)\n",
        "loss = (y - target) ** 2\n",
        "\n",
        "print(f\"w = {w.item():.3f}, b = {b.item():.3f}\")\n",
        "print(f\"z = w*x + b = {z.item():.3f}\")\n",
        "print(f\"y = sigmoid(z) = {y.item():.3f}\")\n",
        "print(f\"loss = (y - target)^2 = {loss.item():.3f}\")\n",
        "\n",
        "# Backward pass\n",
        "loss.backward()\n",
        "\n",
        "print(f\"\\nGradients:\")\n",
        "print(f\"d(loss)/dw = {w.grad.item():.4f}\")\n",
        "print(f\"d(loss)/db = {b.grad.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "jl_Mj01n2Se8",
        "outputId": "d5aba12c-f89e-4f0a-d853-67ceac9a121c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual d(loss)/dw = 0.2954\n",
            "Autograd d(loss)/dw = 0.2954\n",
            "Match: True\n"
          ]
        }
      ],
      "source": [
        "# Let's verify the gradient manually using chain rule\n",
        "# loss = (sigmoid(w*x + b) - target)^2\n",
        "# d(loss)/dw = 2*(y-target) * y*(1-y) * x\n",
        "\n",
        "y_val = y.item()\n",
        "manual_grad_w = 2 * (y_val - target.item()) * y_val * (1 - y_val) * x.item()\n",
        "print(f\"Manual d(loss)/dw = {manual_grad_w:.4f}\")\n",
        "print(f\"Autograd d(loss)/dw = {w.grad.item():.4f}\")\n",
        "print(f\"Match: {abs(manual_grad_w - w.grad.item()) < 1e-6}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MxMb60e2Se8"
      },
      "source": [
        "---\n",
        "\n",
        "# Key Points Summary\n",
        "\n",
        "---\n",
        "\n",
        "## Tensors\n",
        "- Tensors are multi-dimensional arrays, the core data structure\n",
        "- Key attributes: shape, dtype, device\n",
        "- Use float32 for deep learning (memory efficient, fast on GPU)\n",
        "\n",
        "## NumPy Integration\n",
        "- `torch.from_numpy()` shares memory\n",
        "- `torch.tensor()` copies data\n",
        "- `.numpy()` converts to NumPy (CPU only)\n",
        "\n",
        "## GPU Acceleration\n",
        "- Use `device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')`\n",
        "- Move tensors with `.to(device)`\n",
        "- All tensors in an operation must be on the same device\n",
        "\n",
        "## Autograd\n",
        "- Set `requires_grad=True` to track gradients\n",
        "- Call `.backward()` to compute gradients\n",
        "- Gradients accumulate - zero them with `.zero_()`\n",
        "- Use `torch.no_grad()` during inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anPHcS032Se8"
      },
      "source": [
        "---\n",
        "\n",
        "# Interview Tips\n",
        "\n",
        "---\n",
        "\n",
        "## Common Questions\n",
        "\n",
        "**Q: What is a tensor?**\n",
        "A: A tensor is a multi-dimensional array, similar to a NumPy ndarray but with GPU support and automatic differentiation. It's the fundamental data structure in PyTorch.\n",
        "\n",
        "**Q: What is the difference between `.view()` and `.reshape()`?**\n",
        "A: `.view()` requires the tensor to be contiguous in memory and returns a view (shared memory). `.reshape()` works on any tensor and may return a copy if needed. Use `.reshape()` when unsure.\n",
        "\n",
        "**Q: How does autograd work?**\n",
        "A: When `requires_grad=True`, PyTorch builds a computational graph that records operations. When `.backward()` is called, it traverses this graph backwards, applying the chain rule to compute gradients.\n",
        "\n",
        "**Q: Why do we need to zero gradients?**\n",
        "A: PyTorch accumulates gradients by default. This is useful for implementing gradient accumulation across batches, but during normal training, we need to zero gradients before each backward pass.\n",
        "\n",
        "**Q: What is the purpose of `torch.no_grad()`?**\n",
        "A: It temporarily disables gradient computation. Used during inference to save memory and speed up computation since we don't need gradients for predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC8MjVN02Se8"
      },
      "source": [
        "---\n",
        "\n",
        "# Practice Exercises\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKySe81V2Se8"
      },
      "source": [
        "## Exercise 1: Tensor Creation\n",
        "\n",
        "Create a 3x4 tensor with values from a normal distribution with mean=5 and std=2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "GA9PlbsN2Se8"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "tensor = None  # Replace\n",
        "\n",
        "# Verify\n",
        "# print(f\"Shape: {tensor.shape}\")\n",
        "# print(f\"Approximate mean: {tensor.mean():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6DTHONy2Se8"
      },
      "source": [
        "## Exercise 2: Reshaping\n",
        "\n",
        "Given a batch of 32 images of shape (32, 3, 28, 28), flatten each image to feed into a linear layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "pF-dYWQO2Se8"
      },
      "outputs": [],
      "source": [
        "images = torch.randn(32, 3, 28, 28)\n",
        "\n",
        "# Your code here\n",
        "# Reshape to (32, 3*28*28) = (32, 2352)\n",
        "flattened = None  # Replace\n",
        "\n",
        "# print(f\"Flattened shape: {flattened.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8CKhp3j2Se8"
      },
      "source": [
        "## Exercise 3: Gradient Computation\n",
        "\n",
        "For f(x) = x^3 - 2x^2 + x, compute df/dx at x=3 using autograd."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "i42jUcm42Se8"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "x = None  # Create tensor with requires_grad=True\n",
        "# Compute f and backward\n",
        "\n",
        "# The analytical derivative is: 3x^2 - 4x + 1\n",
        "# At x=3: 3*9 - 12 + 1 = 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WckH9PSO2Se9"
      },
      "source": [
        "## Solutions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "g47Fa1VT2Se9",
        "outputId": "b29f7b97-407d-47cf-cb0a-877f4595d210",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exercise 1:\n",
            "Shape: torch.Size([3, 4])\n",
            "Approximate mean: 6.00\n",
            "\n",
            "Exercise 2:\n",
            "Flattened shape: torch.Size([32, 2352])\n",
            "\n",
            "Exercise 3:\n",
            "f(3) = 12.0\n",
            "df/dx at x=3: 16.0 (analytical: 16)\n"
          ]
        }
      ],
      "source": [
        "# Exercise 1\n",
        "print(\"Exercise 1:\")\n",
        "tensor = torch.randn(3, 4) * 2 + 5  # N(0,1) * std + mean\n",
        "print(f\"Shape: {tensor.shape}\")\n",
        "print(f\"Approximate mean: {tensor.mean():.2f}\")\n",
        "\n",
        "# Exercise 2\n",
        "print(\"\\nExercise 2:\")\n",
        "images = torch.randn(32, 3, 28, 28)\n",
        "flattened = images.flatten(start_dim=1)  # or images.view(32, -1)\n",
        "print(f\"Flattened shape: {flattened.shape}\")\n",
        "\n",
        "# Exercise 3\n",
        "print(\"\\nExercise 3:\")\n",
        "x = torch.tensor([3.0], requires_grad=True)\n",
        "f = x**3 - 2*x**2 + x\n",
        "f.backward()\n",
        "print(f\"f(3) = {f.item()}\")\n",
        "print(f\"df/dx at x=3: {x.grad.item()} (analytical: 16)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMxi6Ye52Se9"
      },
      "source": [
        "---\n",
        "\n",
        "## Next Module: [04 - The Neuron](../04_the_neuron/04_neuron.ipynb)\n",
        "\n",
        "Now that we understand PyTorch basics, let's dive into the fundamental building block of neural networks - the artificial neuron."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}