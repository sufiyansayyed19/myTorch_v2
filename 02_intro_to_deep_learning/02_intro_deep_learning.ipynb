{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Module 02: Introduction to Deep Learning\n",
                "\n",
                "**Understanding the Revolution**\n",
                "\n",
                "---\n",
                "\n",
                "## Objectives\n",
                "\n",
                "By the end of this notebook, you will:\n",
                "- Understand the difference between deep learning and traditional machine learning\n",
                "- Know the key milestones in deep learning history\n",
                "- Grasp why deep learning works (Universal Approximation Theorem intuition)\n",
                "- Understand why GPUs are essential for deep learning\n",
                "\n",
                "**Prerequisites:** [Module 01 - Python & Math Prerequisites](../01_python_math_prerequisites/01_prerequisites.ipynb)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "np.random.seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 1: Machine Learning vs Deep Learning\n",
                "\n",
                "---\n",
                "\n",
                "## 1.1 Traditional Machine Learning\n",
                "\n",
                "In traditional ML, the workflow is:\n",
                "\n",
                "1. **Raw Data** -> 2. **Feature Engineering** (manual) -> 3. **Model** -> 4. **Output**\n",
                "\n",
                "The key bottleneck is **feature engineering** - humans must decide what features matter."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example: Recognizing Cats\n",
                "\n",
                "Traditional ML approach:\n",
                "- Extract edges using Sobel filters\n",
                "- Compute color histograms\n",
                "- Calculate texture features (SIFT, HOG)\n",
                "- Feed these features to an SVM or Random Forest\n",
                "\n",
                "**Problem:** What features define a cat? Pointy ears? Fur texture? Whiskers? This requires domain expertise and is hard to generalize."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Traditional ML: Manual feature extraction\n",
                "# Simulate an image as pixel values\n",
                "image = np.random.rand(28, 28)\n",
                "\n",
                "# Manual features (simplified)\n",
                "def extract_features(img):\n",
                "    features = []\n",
                "    features.append(np.mean(img))        # Average pixel value\n",
                "    features.append(np.std(img))         # Standard deviation\n",
                "    features.append(np.max(img))         # Maximum\n",
                "    features.append(np.min(img))         # Minimum\n",
                "    # More features would be needed...\n",
                "    return np.array(features)\n",
                "\n",
                "features = extract_features(image)\n",
                "print(f\"Manually extracted features: {features}\")\n",
                "print(f\"From {28*28} pixels to {len(features)} features\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.2 Deep Learning: Automatic Feature Learning\n",
                "\n",
                "In deep learning, the workflow is:\n",
                "\n",
                "1. **Raw Data** -> 2. **Neural Network** (learns features automatically) -> 3. **Output**\n",
                "\n",
                "The network learns features directly from data - no manual engineering needed!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### How Deep Learning Learns Features\n",
                "\n",
                "A deep network learns hierarchical representations:\n",
                "\n",
                "- **Layer 1:** Edges, simple patterns\n",
                "- **Layer 2:** Textures, simple shapes\n",
                "- **Layer 3:** Object parts (ears, eyes)\n",
                "- **Layer 4+:** Full objects, abstract concepts\n",
                "\n",
                "Each layer builds on the previous, creating increasingly abstract representations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualization: Feature hierarchy\n",
                "fig, axes = plt.subplots(1, 4, figsize=(14, 3))\n",
                "\n",
                "# Layer 1: Edges\n",
                "edge_patterns = np.array([[[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]],\n",
                "                          [[-1, -1, -1], [0, 0, 0], [1, 1, 1]],\n",
                "                          [[0, 1, 0], [1, 1, 1], [0, 1, 0]],\n",
                "                          [[1, 0, -1], [0, 0, 0], [-1, 0, 1]]])\n",
                "\n",
                "for i, ax in enumerate(axes):\n",
                "    if i == 0:\n",
                "        ax.imshow(edge_patterns[0], cmap='gray')\n",
                "        ax.set_title('Layer 1: Edges')\n",
                "    elif i == 1:\n",
                "        # Simulated texture pattern\n",
                "        texture = np.random.rand(8, 8) * 0.5 + 0.25\n",
                "        texture[2:6, 2:6] = 0.8\n",
                "        ax.imshow(texture, cmap='gray')\n",
                "        ax.set_title('Layer 2: Textures')\n",
                "    elif i == 2:\n",
                "        # Simulated part (eye-like)\n",
                "        part = np.zeros((16, 16))\n",
                "        y, x = np.ogrid[:16, :16]\n",
                "        center = (8, 8)\n",
                "        mask = (x - center[0])**2 + (y - center[1])**2 <= 5**2\n",
                "        part[mask] = 1\n",
                "        part[7:9, 7:9] = 0  # pupil\n",
                "        ax.imshow(part, cmap='gray')\n",
                "        ax.set_title('Layer 3: Parts')\n",
                "    else:\n",
                "        # Full object (abstract cat)\n",
                "        cat = np.zeros((32, 32))\n",
                "        cat[8:24, 8:24] = 0.5  # face\n",
                "        cat[4:10, 6:10] = 0.8  # left ear\n",
                "        cat[4:10, 22:26] = 0.8  # right ear\n",
                "        cat[14:16, 12:14] = 1  # left eye\n",
                "        cat[14:16, 18:20] = 1  # right eye\n",
                "        cat[18:20, 14:18] = 0.3  # nose\n",
                "        ax.imshow(cat, cmap='gray')\n",
                "        ax.set_title('Layer 4+: Objects')\n",
                "    ax.axis('off')\n",
                "\n",
                "plt.suptitle('Hierarchical Feature Learning in Deep Networks', fontsize=12)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.3 Key Differences Summary\n",
                "\n",
                "| Aspect | Traditional ML | Deep Learning |\n",
                "|--------|---------------|---------------|\n",
                "| Features | Manual engineering | Automatic learning |\n",
                "| Data needed | Hundreds-thousands | Thousands-millions |\n",
                "| Compute | CPU sufficient | GPU required |\n",
                "| Interpretability | Often clearer | Often \"black box\" |\n",
                "| Domain expertise | Required for features | Less required |\n",
                "| Performance ceiling | Limited by features | Scales with data |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1.4 When to Use Which?\n",
                "\n",
                "**Use Traditional ML when:**\n",
                "- Limited data (hundreds to low thousands)\n",
                "- Need interpretability (medical, finance)\n",
                "- Structured data (tables, not images/text)\n",
                "- Limited compute resources\n",
                "\n",
                "**Use Deep Learning when:**\n",
                "- Large dataset available\n",
                "- Complex patterns (images, speech, text)\n",
                "- Compute resources available\n",
                "- State-of-the-art performance needed"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 2: History and Evolution\n",
                "\n",
                "---\n",
                "\n",
                "## 2.1 Timeline of Key Milestones\n",
                "\n",
                "Understanding history helps you understand why things are the way they are."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Timeline visualization\n",
                "milestones = {\n",
                "    1958: \"Perceptron\\n(Rosenblatt)\",\n",
                "    1969: \"XOR Problem\\nAI Winter begins\",\n",
                "    1986: \"Backpropagation\\n(Hinton et al.)\",\n",
                "    1998: \"LeNet-5\\n(LeCun)\",\n",
                "    2006: \"Deep Belief Nets\\nDeep Learning coined\",\n",
                "    2012: \"AlexNet\\nImageNet breakthrough\",\n",
                "    2014: \"GANs, VGGNet\\nDropout\",\n",
                "    2017: \"Transformer\\nAttention mechanism\",\n",
                "    2018: \"BERT\\n(NLP revolution)\",\n",
                "    2020: \"GPT-3\\n175B parameters\",\n",
                "    2022: \"ChatGPT\\nAI goes mainstream\"\n",
                "}\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(16, 6))\n",
                "\n",
                "years = list(milestones.keys())\n",
                "ax.set_xlim(1955, 2025)\n",
                "ax.set_ylim(-1, 1)\n",
                "\n",
                "# Draw timeline\n",
                "ax.axhline(y=0, color='gray', linewidth=2)\n",
                "\n",
                "for i, (year, event) in enumerate(milestones.items()):\n",
                "    y_offset = 0.5 if i % 2 == 0 else -0.5\n",
                "    ax.scatter([year], [0], color='blue', s=100, zorder=5)\n",
                "    ax.plot([year, year], [0, y_offset*0.8], 'b-', linewidth=1)\n",
                "    ax.text(year, y_offset, event, ha='center', va='center' if y_offset > 0 else 'top',\n",
                "            fontsize=8, bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
                "\n",
                "ax.set_xlabel('Year', fontsize=12)\n",
                "ax.set_title('Deep Learning Timeline: Key Milestones', fontsize=14)\n",
                "ax.set_yticks([])\n",
                "ax.spines['top'].set_visible(False)\n",
                "ax.spines['right'].set_visible(False)\n",
                "ax.spines['left'].set_visible(False)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.2 Key Historical Moments\n",
                "\n",
                "### The Perceptron (1958)\n",
                "Frank Rosenblatt invented the perceptron - a single artificial neuron that could learn. The media claimed it would solve AI.\n",
                "\n",
                "### AI Winter (1969-1980s)\n",
                "Minsky & Papert showed perceptrons couldn't solve XOR. Funding dried up. The \"AI Winter\" began.\n",
                "\n",
                "### Backpropagation (1986)\n",
                "Hinton, Rumelhart, and Williams popularized backpropagation - enabling training of multi-layer networks. This solved XOR!\n",
                "\n",
                "### ImageNet Moment (2012)\n",
                "AlexNet (Krizhevsky, Sutskever, Hinton) won ImageNet by a huge margin using deep CNNs on GPUs. This sparked the current revolution."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2.3 Why the Sudden Success?\n",
                "\n",
                "Three factors converged:\n",
                "\n",
                "1. **Data:** Internet produced massive datasets (ImageNet, Wikipedia, etc.)\n",
                "2. **Compute:** GPUs made training 10-100x faster\n",
                "3. **Algorithms:** Better architectures, initialization, regularization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualization: The three factors\n",
                "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
                "\n",
                "# Data growth\n",
                "years = np.arange(2000, 2024)\n",
                "data_volume = 0.1 * np.exp(0.4 * (years - 2000))  # Exponential growth\n",
                "axes[0].plot(years, data_volume, 'b-', linewidth=2)\n",
                "axes[0].fill_between(years, data_volume, alpha=0.3)\n",
                "axes[0].set_xlabel('Year')\n",
                "axes[0].set_ylabel('Data Volume (relative)')\n",
                "axes[0].set_title('1. DATA: Exponential Growth')\n",
                "axes[0].set_yscale('log')\n",
                "\n",
                "# Compute (GPU TFLOPs)\n",
                "gpu_years = [2008, 2010, 2012, 2014, 2016, 2018, 2020, 2022]\n",
                "gpu_flops = [0.5, 1, 3, 5, 10, 15, 30, 80]  # Approximate TFLOPs\n",
                "axes[1].bar(gpu_years, gpu_flops, color='green', alpha=0.7, width=1.5)\n",
                "axes[1].set_xlabel('Year')\n",
                "axes[1].set_ylabel('GPU TFLOPs')\n",
                "axes[1].set_title('2. COMPUTE: GPU Power')\n",
                "\n",
                "# Algorithm improvements (ImageNet error rate)\n",
                "alg_years = [2010, 2012, 2014, 2015, 2016, 2017, 2018]\n",
                "error_rates = [28, 16, 7, 4, 3, 2.5, 2]  # Approximate top-5 error %\n",
                "axes[2].plot(alg_years, error_rates, 'r-o', linewidth=2, markersize=8)\n",
                "axes[2].axhline(y=5.1, color='gray', linestyle='--', label='Human level')\n",
                "axes[2].set_xlabel('Year')\n",
                "axes[2].set_ylabel('ImageNet Error Rate (%)')\n",
                "axes[2].set_title('3. ALGORITHMS: Better Performance')\n",
                "axes[2].legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 3: Why Deep Learning Works\n",
                "\n",
                "---\n",
                "\n",
                "## 3.1 The Universal Approximation Theorem\n",
                "\n",
                "**Theorem:** A feedforward neural network with a single hidden layer containing a finite number of neurons can approximate any continuous function on a compact subset of R^n, given appropriate activation functions.\n",
                "\n",
                "**In simple terms:** A neural network can learn ANY function if it has enough neurons.\n",
                "\n",
                "This is why neural networks are so powerful - they're universal function approximators!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.2 Intuition: How Can Neurons Approximate Any Function?\n",
                "\n",
                "Think of it like this:\n",
                "- Each neuron acts as a \"step\" or \"bump\"\n",
                "- By combining many small steps, you can approximate any curve\n",
                "- More neurons = finer approximation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Demonstration: Approximating a function with \"bumps\"\n",
                "def target_function(x):\n",
                "    return np.sin(2 * x) + 0.5 * np.cos(4 * x)\n",
                "\n",
                "def sigmoid(x):\n",
                "    return 1 / (1 + np.exp(-x))\n",
                "\n",
                "def create_bump(x, center, width, height):\n",
                "    \"\"\"Create a sigmoid-based bump at a location.\"\"\"\n",
                "    left = sigmoid((x - center + width/2) * 10)\n",
                "    right = sigmoid(-(x - center - width/2) * 10)\n",
                "    return height * left * right\n",
                "\n",
                "x = np.linspace(-3, 3, 500)\n",
                "y_target = target_function(x)\n",
                "\n",
                "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
                "\n",
                "for idx, n_bumps in enumerate([2, 5, 10, 20]):\n",
                "    ax = axes[idx // 2, idx % 2]\n",
                "    \n",
                "    # Create approximation with n bumps\n",
                "    centers = np.linspace(-2.5, 2.5, n_bumps)\n",
                "    width = 5 / n_bumps\n",
                "    \n",
                "    approximation = np.zeros_like(x)\n",
                "    for c in centers:\n",
                "        # Height determined by target function at center\n",
                "        h = target_function(c)\n",
                "        approximation += create_bump(x, c, width, h)\n",
                "    \n",
                "    ax.plot(x, y_target, 'b-', linewidth=2, label='Target function')\n",
                "    ax.plot(x, approximation, 'r--', linewidth=2, label=f'Approximation ({n_bumps} bumps)')\n",
                "    ax.set_title(f'{n_bumps} Neurons/Bumps')\n",
                "    ax.legend()\n",
                "    ax.set_xlim(-3, 3)\n",
                "    ax.set_ylim(-2, 2)\n",
                "\n",
                "plt.suptitle('Universal Approximation: More Neurons = Better Approximation', fontsize=12)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.3 Why Depth Matters\n",
                "\n",
                "The theorem says ONE hidden layer is enough. So why go deep?\n",
                "\n",
                "**Depth gives efficiency:**\n",
                "- A deep network can represent some functions with exponentially fewer neurons than a shallow one\n",
                "- Shallow: might need 2^n neurons\n",
                "- Deep: might need only O(n) neurons\n",
                "\n",
                "**Depth gives hierarchy:**\n",
                "- Early layers learn simple features\n",
                "- Later layers compose them into complex features\n",
                "- This matches the structure of real-world data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualization: Shallow vs Deep\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "# Shallow network\n",
                "ax = axes[0]\n",
                "# Input layer\n",
                "for i in range(3):\n",
                "    ax.scatter([0], [i], s=300, c='lightblue', edgecolors='black', zorder=5)\n",
                "# Hidden layer (many neurons needed)\n",
                "for i in range(8):\n",
                "    ax.scatter([1], [i*0.4 - 0.4], s=300, c='lightgreen', edgecolors='black', zorder=5)\n",
                "# Output\n",
                "ax.scatter([2], [1], s=300, c='salmon', edgecolors='black', zorder=5)\n",
                "\n",
                "# Connections\n",
                "for i in range(3):\n",
                "    for j in range(8):\n",
                "        ax.plot([0, 1], [i, j*0.4-0.4], 'gray', alpha=0.3, linewidth=0.5)\n",
                "for j in range(8):\n",
                "    ax.plot([1, 2], [j*0.4-0.4, 1], 'gray', alpha=0.3, linewidth=0.5)\n",
                "\n",
                "ax.set_xlim(-0.5, 2.5)\n",
                "ax.set_title('Shallow Network\\n(Many neurons in one layer)')\n",
                "ax.axis('off')\n",
                "\n",
                "# Deep network\n",
                "ax = axes[1]\n",
                "# Input layer\n",
                "for i in range(3):\n",
                "    ax.scatter([0], [i*0.5+0.25], s=300, c='lightblue', edgecolors='black', zorder=5)\n",
                "# Hidden layers (fewer neurons per layer)\n",
                "for layer in range(1, 4):\n",
                "    for i in range(4):\n",
                "        ax.scatter([layer], [i*0.4+0.3], s=300, c='lightgreen', edgecolors='black', zorder=5)\n",
                "# Output\n",
                "ax.scatter([4], [0.9], s=300, c='salmon', edgecolors='black', zorder=5)\n",
                "\n",
                "# Connections\n",
                "prev_positions = [i*0.5+0.25 for i in range(3)]\n",
                "for layer in range(1, 4):\n",
                "    curr_positions = [i*0.4+0.3 for i in range(4)]\n",
                "    for p in prev_positions:\n",
                "        for c in curr_positions:\n",
                "            ax.plot([layer-1, layer], [p, c], 'gray', alpha=0.3, linewidth=0.5)\n",
                "    prev_positions = curr_positions\n",
                "\n",
                "for p in prev_positions:\n",
                "    ax.plot([3, 4], [p, 0.9], 'gray', alpha=0.3, linewidth=0.5)\n",
                "\n",
                "ax.set_xlim(-0.5, 4.5)\n",
                "ax.set_title('Deep Network\\n(Fewer neurons, more layers)')\n",
                "ax.axis('off')\n",
                "\n",
                "plt.suptitle('Shallow vs Deep: Same Representational Power, Different Efficiency', fontsize=12)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.4 Representation Learning\n",
                "\n",
                "The real power of deep learning is **learning representations** - finding the right way to encode information.\n",
                "\n",
                "- Raw pixels are a poor representation for classification\n",
                "- The network learns to transform pixels into features that make classification easy\n",
                "- The final layer sees \"cat-like features\" not pixels"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Part 4: Hardware - CPUs vs GPUs\n",
                "\n",
                "---\n",
                "\n",
                "## 4.1 Why GPUs?\n",
                "\n",
                "Neural network training is dominated by matrix multiplication. Let's see why GPUs excel at this."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### CPU Architecture\n",
                "- Few cores (4-16 typically)\n",
                "- Each core is very powerful\n",
                "- Optimized for sequential tasks\n",
                "- Good for: complex logic, branching code\n",
                "\n",
                "### GPU Architecture\n",
                "- Thousands of small cores (hundreds to thousands)\n",
                "- Each core is simple\n",
                "- Optimized for parallel tasks\n",
                "- Good for: same operation on many data points"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualization: CPU vs GPU architecture\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# CPU\n",
                "ax = axes[0]\n",
                "# 8 big cores\n",
                "for i in range(2):\n",
                "    for j in range(4):\n",
                "        rect = plt.Rectangle((j*1.2, i*1.2), 1, 1, fill=True, \n",
                "                             facecolor='royalblue', edgecolor='black', linewidth=2)\n",
                "        ax.add_patch(rect)\n",
                "        ax.text(j*1.2 + 0.5, i*1.2 + 0.5, f'Core\\n{i*4+j+1}', \n",
                "                ha='center', va='center', fontsize=10, color='white', fontweight='bold')\n",
                "\n",
                "ax.set_xlim(-0.5, 5.5)\n",
                "ax.set_ylim(-0.5, 3)\n",
                "ax.set_aspect('equal')\n",
                "ax.set_title('CPU: 8 Powerful Cores\\n(Sequential processing)', fontsize=12)\n",
                "ax.axis('off')\n",
                "\n",
                "# GPU\n",
                "ax = axes[1]\n",
                "# Many small cores\n",
                "for i in range(8):\n",
                "    for j in range(16):\n",
                "        rect = plt.Rectangle((j*0.35, i*0.35), 0.3, 0.3, fill=True, \n",
                "                             facecolor='green', edgecolor='darkgreen', linewidth=0.5)\n",
                "        ax.add_patch(rect)\n",
                "\n",
                "ax.set_xlim(-0.5, 6)\n",
                "ax.set_ylim(-0.5, 3.5)\n",
                "ax.set_aspect('equal')\n",
                "ax.set_title('GPU: 128+ Simple Cores\\n(Parallel processing)', fontsize=12)\n",
                "ax.axis('off')\n",
                "\n",
                "plt.suptitle('CPU vs GPU Architecture', fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4.2 Matrix Multiplication is Parallel\n",
                "\n",
                "Each element of the output matrix can be computed independently:\n",
                "\n",
                "```\n",
                "C[i,j] = sum(A[i,:] * B[:,j])\n",
                "```\n",
                "\n",
                "For a 1000x1000 matrix, that's 1,000,000 independent computations - perfect for GPU!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simulate CPU vs GPU speed difference\n",
                "import time\n",
                "\n",
                "sizes = [100, 500, 1000, 2000]\n",
                "times_sequential = []\n",
                "times_parallel = []\n",
                "\n",
                "for size in sizes:\n",
                "    A = np.random.randn(size, size)\n",
                "    B = np.random.randn(size, size)\n",
                "    \n",
                "    # NumPy uses optimized BLAS (simulates multi-core/parallel)\n",
                "    start = time.time()\n",
                "    C = A @ B\n",
                "    times_parallel.append(time.time() - start)\n",
                "    \n",
                "    # Simulate sequential (just the number of operations)\n",
                "    # Each element needs 'size' multiplications and additions\n",
                "    ops = size ** 3  # O(n^3) operations\n",
                "    times_sequential.append(ops / 1e9)  # Normalize\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(10, 5))\n",
                "\n",
                "x = np.arange(len(sizes))\n",
                "width = 0.35\n",
                "\n",
                "bars1 = ax.bar(x - width/2, times_sequential, width, label='Sequential (simulated)', color='royalblue')\n",
                "bars2 = ax.bar(x + width/2, times_parallel, width, label='Parallel (NumPy BLAS)', color='green')\n",
                "\n",
                "ax.set_xlabel('Matrix Size')\n",
                "ax.set_ylabel('Time (relative)')\n",
                "ax.set_title('Matrix Multiplication: Sequential vs Parallel')\n",
                "ax.set_xticks(x)\n",
                "ax.set_xticklabels([f'{s}x{s}' for s in sizes])\n",
                "ax.legend()\n",
                "ax.set_yscale('log')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"Key insight: As matrices get larger, parallelization advantage grows!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4.3 CUDA and PyTorch\n",
                "\n",
                "**CUDA** is NVIDIA's platform for GPU computing. PyTorch uses CUDA to run operations on GPU.\n",
                "\n",
                "```python\n",
                "import torch\n",
                "\n",
                "# Check if GPU is available\n",
                "if torch.cuda.is_available():\n",
                "    device = torch.device('cuda')\n",
                "else:\n",
                "    device = torch.device('cpu')\n",
                "\n",
                "# Move tensor to GPU\n",
                "x = torch.randn(1000, 1000)\n",
                "x = x.to(device)  # Now on GPU!\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability (will work even without GPU)\n",
                "try:\n",
                "    import torch\n",
                "    print(f\"PyTorch version: {torch.__version__}\")\n",
                "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "    if torch.cuda.is_available():\n",
                "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                "    else:\n",
                "        print(\"Running on CPU - GPU not available\")\n",
                "except ImportError:\n",
                "    print(\"PyTorch not installed. Install with: pip install torch\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4.4 Practical GPU Tips\n",
                "\n",
                "1. **Batch operations:** GPU is efficient when processing many samples at once\n",
                "2. **Minimize CPU-GPU transfers:** Moving data is expensive\n",
                "3. **Use appropriate batch sizes:** Too small wastes GPU; too large runs out of memory\n",
                "4. **Monitor GPU memory:** Use `nvidia-smi` or `torch.cuda.memory_allocated()`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Key Points Summary\n",
                "\n",
                "---\n",
                "\n",
                "## Deep Learning vs Traditional ML\n",
                "- Traditional ML requires manual feature engineering\n",
                "- Deep learning learns features automatically from data\n",
                "- Deep learning scales better with more data\n",
                "\n",
                "## History\n",
                "- Perceptron (1958) -> AI Winter -> Backpropagation (1986) -> ImageNet (2012) -> Today\n",
                "- Three factors enabled the revolution: Data + Compute + Algorithms\n",
                "\n",
                "## Why Deep Learning Works\n",
                "- Universal Approximation: networks can learn any function\n",
                "- Depth gives efficiency and hierarchical representations\n",
                "- Networks learn good representations of data\n",
                "\n",
                "## Hardware\n",
                "- GPUs have many simple cores vs CPU's few powerful cores\n",
                "- Matrix multiplication is highly parallel\n",
                "- PyTorch uses CUDA to leverage GPU power"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Interview Tips\n",
                "\n",
                "---\n",
                "\n",
                "## Common Questions\n",
                "\n",
                "**Q: What is the difference between ML and DL?**\n",
                "A: Traditional ML requires manual feature engineering while deep learning learns features automatically. DL uses neural networks with multiple layers to learn hierarchical representations from raw data.\n",
                "\n",
                "**Q: Why did deep learning take off around 2012?**\n",
                "A: Three factors converged: (1) Large datasets like ImageNet became available, (2) GPUs made training feasible, and (3) Algorithmic improvements like ReLU and dropout improved training.\n",
                "\n",
                "**Q: What is the Universal Approximation Theorem?**\n",
                "A: It states that a neural network with a single hidden layer can approximate any continuous function, given enough neurons. This explains why neural networks are so versatile.\n",
                "\n",
                "**Q: Why use GPUs for deep learning?**\n",
                "A: Neural network training is dominated by matrix operations, which are highly parallel. GPUs have thousands of cores designed for parallel computation, making them 10-100x faster than CPUs for this workload.\n",
                "\n",
                "**Q: Why go deep? Why not just one wide layer?**\n",
                "A: Deep networks can represent complex functions more efficiently than shallow ones. They also learn hierarchical features naturally - simple features in early layers, complex in later layers."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# Practice Exercises\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exercise 1: Feature Engineering\n",
                "\n",
                "You have a dataset of house prices with features: square footage, bedrooms, bathrooms, year built. For traditional ML, what additional features might you engineer?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your answer here (as comments)\n",
                "# Example engineered features:\n",
                "# 1. ?\n",
                "# 2. ?\n",
                "# 3. ?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exercise 2: When to Use What?\n",
                "\n",
                "For each scenario, would you recommend traditional ML or deep learning? Why?\n",
                "\n",
                "1. Predicting customer churn with 500 customers and 20 features\n",
                "2. Classifying 1 million images into 1000 categories\n",
                "3. Predicting stock prices based on historical data\n",
                "4. Translating English to French"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your answers here\n",
                "# 1. \n",
                "# 2. \n",
                "# 3. \n",
                "# 4. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exercise 3: GPU Memory Estimation\n",
                "\n",
                "A neural network has:\n",
                "- Input: 1000 features\n",
                "- Hidden layer 1: 512 neurons\n",
                "- Hidden layer 2: 256 neurons\n",
                "- Output: 10 classes\n",
                "\n",
                "How many parameters (weights + biases) does it have? (Assume float32 = 4 bytes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your calculation here\n",
                "# Layer 1: ? weights + ? biases\n",
                "# Layer 2: ? weights + ? biases\n",
                "# Output: ? weights + ? biases\n",
                "# Total: ?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Solutions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 1 Solution\n",
                "print(\"Exercise 1 - Engineered features for house prices:\")\n",
                "print(\"1. Price per square foot (could compute after prediction)\")\n",
                "print(\"2. Age of house (current year - year built)\")\n",
                "print(\"3. Bathroom to bedroom ratio\")\n",
                "print(\"4. Square footage per bedroom\")\n",
                "print(\"5. Polynomial features (sqft^2, interactions)\")\n",
                "print(\"6. Log of square footage (if skewed)\")\n",
                "\n",
                "print(\"\\nExercise 2 - ML vs DL:\")\n",
                "print(\"1. Customer churn (500 samples): Traditional ML - not enough data for DL\")\n",
                "print(\"2. 1M images: Deep Learning - large data, complex patterns\")\n",
                "print(\"3. Stock prices: Either/Both - depends on approach, DL for patterns\")\n",
                "print(\"4. Translation: Deep Learning - sequential data, complex relationships\")\n",
                "\n",
                "print(\"\\nExercise 3 - Parameter count:\")\n",
                "layer1 = 1000 * 512 + 512  # weights + biases\n",
                "layer2 = 512 * 256 + 256\n",
                "output_layer = 256 * 10 + 10\n",
                "total = layer1 + layer2 + output_layer\n",
                "print(f\"Layer 1: {1000}*{512} + {512} = {layer1:,}\")\n",
                "print(f\"Layer 2: {512}*{256} + {256} = {layer2:,}\")\n",
                "print(f\"Output: {256}*{10} + {10} = {output_layer:,}\")\n",
                "print(f\"Total parameters: {total:,}\")\n",
                "print(f\"Memory (float32): {total * 4 / 1e6:.2f} MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Next Module: [03 - PyTorch Fundamentals](../03_pytorch_fundamentals/03_pytorch_fundamentals.ipynb)\n",
                "\n",
                "Now that we understand what deep learning is and why it works, let's dive into PyTorch - the framework we'll use to build neural networks."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}